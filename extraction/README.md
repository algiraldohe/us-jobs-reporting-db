# Extraction Container
App designed for retrieving Daily Job Opportunity Announcements data for a given keyword spaning a time frame.

## Table of content

| Content | Description |
| :------ | :---------- |
| [1. Installation](#1-installation) | Steps for dependencies installation |
| [2. Guidelines](#2-guidelines) | Code structure and layout |
| [3. APP Usage](#3-app-usage) | How to use the APP |

## 1. Installation

### 1.1 Dependencies installation

To install this project, it is recommended to use `virtualenv` python package. By default, macOS has installed the `python3` binary. So the following commands should work:


Install virtualenv to create an environment for your python packages:
```
python3 -m pip install virtualenv
```

If pip is not installed follow the guide at https://pip.pypa.io/en/stable/installation/. Use get-pip.py code.

Create an environment:
```
python3 -m virtualenv -p python3 venv
```

Activate the environment:
```
source venv/bin/activate
```

Install python dependencies:

```
pip install -r dev-requirements.txt -r requirements.txt
```

Check linting (linting configuration is set in .flake8):

```
flake8
```

Check more linting:

```
black -l 88 --preview .
```

```
isort --profile=black .
```

Check docstyle in the code (docstyle configuration is set in .pydocstyle):

```
pydocstyle
```

## 2. Guidelines

### 2.1 Files Structure

The main idea was to split the code into three cores: application, domain and infrastructure (see diagram).

![ProjectStructure](https://github.com/algiraldohe/us-jobs-reporting-db/blob/development/docs/images/ProjectStructure-Extraction.png)

All code relevant to how a user access data (HTTP requests, Console) should be in the application folder, that is why all frameworks code is located in this folder.

Inside `application` folder, there is a folder called `adapters`, inside, contains functions or classes that allow us to transform the requests from the user into actions that will be carried by the `domain` or business logic. This favours the possibility of including easily new adapters for the user to interact with the app, for example in a cloud implementation the request should be translated from an HTTP request, but the logic should remain doing exactly the same.

In `domain` folder is located all the code related to the business logic, it does not care about what is the body of the request containing, or what is the database we are querying, or where are we storing the data. This code uses the adapters generated by the `infrastructure` folder to get and perform what it needs in a decoupled way.

In `infrastructure` folder we have all the code related to persistence (databases, file storage), notifications (sms, mails), local services (file navigation, local storage) and external sources (Google APIs). The idea is to have adapters (classes) that handle all these sources' logic so that `domain` code can change of adapter easily and keep working.


## 3. APP Usage

### 3.1 Components
For the correct functioning of the application I have laid down the following:

- `Makefile` is used alias the command's instructions to manipulate, set up and run the service.
- `Dockerfile` with the container configuration and required images and parameters.
- Env files `.env` and `.env.docker` with environment variables used in the extraction process one for running the service locally and the other to run it with docker.
  
  Additionally, there's and `.env.template` for the env files in order to provide the structure and variables that need to be filled for the correct functionality of the code. 
    ***Note: (Keep the env variable FILESTORAGE=../file-storage/)***

**Running Locally**
`python3 main.py --console "extract_jobs" "data engineering" 2 "Chicago, Illinois"`

### Commands 

```bash
# Assuming you are just outside of the cloned repo
cd us-jobs-reporting-db

# 1. change the directory to the `extraction` service director
cd extraction

# 2. build the image of the container using the Makefile
make build

# 3. run the service to extract and save the data from USA Jobs reporting database
make run

```

After the execution of the above commands, the `file-storage` folder will be created and there will be a `YYYY-mm-dd-us-jobs.json` file inside, corresponding to the date the process was run.